{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of train, validation and test folders\n",
    "\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def img_train_test_split(img_source_dir, train_size, validation_size):\n",
    "    \"\"\"\n",
    "    Randomly splits images over a train and validation folder, while preserving the folder structure\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_source_dir : string\n",
    "        Path to the folder with the images to be split. Can be absolute or relative path   \n",
    "        \n",
    "    train_size : float\n",
    "        Proportion of the original images that need to be copied in the subdirectory in the train folder\n",
    "    \"\"\"    \n",
    "    if not (isinstance(img_source_dir, str)):\n",
    "        raise AttributeError('img_source_dir must be a string')\n",
    "        \n",
    "    if not os.path.exists(img_source_dir):\n",
    "        raise OSError('img_source_dir does not exist')\n",
    "        \n",
    "    if not (isinstance(train_size, float)):\n",
    "        raise AttributeError('train_size must be a float')\n",
    "        \n",
    "    # Set up empty folder structure if not exists\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    else:\n",
    "        if not os.path.exists('data/train'):\n",
    "            os.makedirs('data/train')\n",
    "        if not os.path.exists('data/validation'):\n",
    "            os.makedirs('data/validation')\n",
    "        if not os.path.exists('data/test'):\n",
    "            os.makedirs('data/test')\n",
    "            \n",
    "    # Get the subdirectories in the main image folder\n",
    "    subdirs = [subdir for subdir in os.listdir(img_source_dir) if os.path.isdir(os.path.join(img_source_dir, subdir))]\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        subdir_fullpath = os.path.join(img_source_dir, subdir)\n",
    "        if len(os.listdir(subdir_fullpath)) == 0:\n",
    "            print(subdir_fullpath + ' is empty')\n",
    "            break\n",
    "\n",
    "        train_subdir = os.path.join('data/train', subdir)\n",
    "        validation_subdir = os.path.join('data/validation', subdir)\n",
    "        test_subdir = os.path.join('data/test', subdir)\n",
    "\n",
    "        # Create subdirectories in train and validation folders\n",
    "        if not os.path.exists(train_subdir):\n",
    "            os.makedirs(train_subdir)\n",
    "\n",
    "        if not os.path.exists(validation_subdir):\n",
    "            os.makedirs(validation_subdir)\n",
    "            \n",
    "        if not os.path.exists(test_subdir):\n",
    "            os.makedirs(test_subdir)\n",
    "\n",
    "        train_counter = 0\n",
    "        validation_counter = 0\n",
    "        test_counter = 0\n",
    "\n",
    "        # Randomly assign an image to train or validation folder\n",
    "        for filename in os.listdir(subdir_fullpath):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "                fileparts = filename.split('.')\n",
    "\n",
    "                if random.uniform(0, 1) <= train_size:\n",
    "                    copyfile(os.path.join(subdir_fullpath, filename),\n",
    "                             os.path.join(train_subdir, str(train_counter) + '.' + fileparts[1]))\n",
    "                    train_counter += 1\n",
    "                elif random.uniform(0, 1) <= validation_size:\n",
    "                    copyfile(os.path.join(subdir_fullpath, filename),\n",
    "                             os.path.join(validation_subdir, str(validation_counter) + '.' + fileparts[1]))\n",
    "                    validation_counter += 1\n",
    "                else :\n",
    "                    copyfile(os.path.join(subdir_fullpath, filename),\n",
    "                             os.path.join(test_subdir, str(test_counter) + '.' + fileparts[1]))\n",
    "                    test_counter += 1\n",
    "                    \n",
    "        print('Copied ' + str(train_counter) + ' images to data/train/' + subdir)\n",
    "        print('Copied ' + str(validation_counter) + ' images to data/validation/' + subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9971675efec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/Images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "img_train_test_split('../data/Images', 0.7, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120 total dog categories.\n",
      "There are 20580 total dog images.\n",
      "\n",
      "There are 14444 training dog images.\n",
      "There are 1255 validation dog images.\n",
      "There are 4881 test dog images.\n"
     ]
    }
   ],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']))\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('../data/train')\n",
    "valid_files, valid_targets = load_dataset('../data/validation')\n",
    "test_files, test_targets = load_dataset('../data/test')\n",
    "\n",
    "# load list of dog names\n",
    "# the [20:-1] portion simply removes the filepath and folder number\n",
    "dog_names = [item[25:-1] for item in sorted(glob(\"../data/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dog_img, dog_targets = load_dataset('../data/Images')\n",
    "\n",
    "# load list of dog names\n",
    "dog_breed = [item[25:-1] for item in sorted(glob(\"../data/Images/*/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14444 images belonging to 120 classes.\n",
      "Found 1255 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "# training image augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History \n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration I will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range = 30,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest')\n",
    "\n",
    "# This is the augmentation configuration I will use for testing/validation... just a rescale\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = xception.preprocess_input,\n",
    "                                  rescale=1./255)\n",
    "\n",
    "# This is the generator which will read pictures found in my training subset\n",
    "train_generator = train_datagen.flow_from_directory('../data/train/',\n",
    "                                                    target_size = (224, 224),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'categorical')\n",
    "\n",
    "# This is the generator for validation data\n",
    "validation_generator = test_datagen.flow_from_directory('../data/validation/',\n",
    "                                                        target_size = (224, 224),\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0bb02552bc20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "shape(train_generator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3693dbe72dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpath_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# loads RGB image as PIL.Image.Image type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = paths_to_tensor(train_generator).astype('float32')\n",
    "valid_tensors = paths_to_tensor(validation_generator).astype('float32')\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 133 classes\n",
    "predictions = Dense(120, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "new_model.compile(loss=\"categorical_crossentropy\", \n",
    "                  optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1673s - loss: 4.9147 - accuracy: 0.0106 - val_loss: 4.7251 - val_accuracy: 0.0132\n",
      "Epoch 2/50\n",
      " - 1631s - loss: 4.8240 - accuracy: 0.0157 - val_loss: 4.9377 - val_accuracy: 0.0085\n",
      "Epoch 3/50\n",
      " - 5514s - loss: 4.7180 - accuracy: 0.0264 - val_loss: 4.7610 - val_accuracy: 0.0108\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = 6680 // batch_size,\n",
    "                        epochs = 50,\n",
    "                        validation_data = validation_generator,\n",
    "                        validation_steps = 835 // batch_size,\n",
    "                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
